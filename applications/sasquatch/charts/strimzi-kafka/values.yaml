# Default values for kafka used in Sasquatch.
cluster:
  # -- Name used for the Kafka cluster, and used by Strimzi for many annotations.
  name: sasquatch

kafka:
  # -- Version of Kafka to deploy.
  version: "3.5.1"
  # -- Number of Kafka broker replicas to run.
  replicas: 3
  storage:
    # -- Size of the backing storage disk for each of the Kafka brokers.
    size: 500Gi
    # -- Name of a StorageClass to use when requesting persistent volumes.
    storageClassName: ""
  config:
    # -- Number of minutes for a consumer group's offsets to be retained.
    offsets.retention.minutes: 4320
    # -- Number of days for a topic's data to be retained.
    log.retention.hours: 72
    # -- Maximum retained number of bytes for a topic's data.
    log.retention.bytes: "429496729600"
    # -- The largest record batch size allowed by Kafka.
    message.max.bytes: 10485760
    # -- The number of bytes of messages to attempt to fetch for each partition.
    replica.fetch.max.bytes: 10485760
    # -- Replica lag time can't be smaller than request.timeout.ms configuration in kafka connect.
    replica.lag.time.max.ms: 120000

  listeners:
    plain:
      # -- Whether internal plaintext listener is enabled.
      enabled: true

    tls:
      # -- Whether internal TLS listener is enabled.
      enabled: true

    external:
      # -- Whether external listener is enabled.
      enabled: true

  externalListener:
    tls:
      # -- Whether TLS encryption is enabled.
      enabled: false
      # -- Name of a ClusterIssuer capable of provisioning a TLS certificate for the broker.
      certIssuerName: "letsencrypt-dns"

    bootstrap:
      # -- The loadbalancer is requested with the IP address specified in this field.
      # This feature depends on whether the underlying cloud provider supports specifying the loadBalancerIP when a load balancer is created.
      # This field is ignored if the cloud provider does not support the feature.
      # Once the IP address is provisioned this option make it possible to pin the IP address.
      # We can request the same IP next time it is provisioned. This is important because
      # it lets us configure a DNS record, associating a hostname with that pinned IP address.
      loadBalancerIP: ""
      # -- Name used for TLS hostname verification.
      host: ""
      # -- Annotations that will be added to the Ingress, Route, or Service resource.
      annotations: {}

    # -- Borkers configuration. host is used in the brokers' advertised.brokers configuration and for TLS hostname verification.
    # The format is a list of maps.
    brokers: []
    # For example:
    # brokers:
    #   - loadBalancerIP: "192.168.1.1"
    #     host: broker-0.example
    #     annotations:
    #       metallb.universe.tf/address-pool: sdf-dmz
    #   - loadBalancerIP: "192.168.1.2"
    #     host: broker-1.example
    #     annotations:
    #       metallb.universe.tf/address-pool: sdf-dmz

  # -- Affinity for Kafka pod assignment.
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: "app.kubernetes.io/name"
            operator: In
            values:
            - kafka
        topologyKey: "kubernetes.io/hostname"

  # -- Tolerations for Kafka broker pod assignment.
  tolerations: []

zookeeper:
  # -- Number of Zookeeper replicas to run.
  replicas: 3
  storage:
    # -- Size of the backing storage disk for each of the Zookeeper instances.
    size: 100Gi
    # -- Name of a StorageClass to use when requesting persistent volumes.
    storageClassName: ""

  # -- Affinity for Zookeeper pod assignment.
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: "app.kubernetes.io/name"
            operator: In
            values:
            - zookeeper
        topologyKey: "kubernetes.io/hostname"

  # -- Tolerations for Zookeeper pod assignment.
  tolerations: []

connect:
  # -- Enable Kafka Connect.
  enabled: true
  # -- Custom strimzi-kafka image with connector plugins used by sasquatch.
  image: ghcr.io/lsst-sqre/strimzi-0.36.1-kafka-3.5.1:tickets-dm-40655
  # -- Number of Kafka Connect replicas to run.
  replicas: 3

registry:
  # -- Name of the topic used by the Schema Registry
  schemaTopic: registry-schemas

# -- A list of usernames for users who should have global admin permissions.
# These users will be created, along with their credentials.
superusers:
- kafka-admin

users:
  replicator:
    # -- Enabled user replicator (used by Mirror Maker 2 and required at both source and target clusters)
    enabled: false

  tsSalKafka:
    # -- Enable user ts-salkafka.
    enabled: true

  kafdrop:
    # -- Enable user Kafdrop (deployed by parent Sasquatch chart).
    enabled: true

  telegraf:
    # -- Enable user telegraf (deployed by parent Sasquatch chart)
    enabled: true

  promptProcessing:
    # -- Enable user prompt-processing
    enabled: true

  kafkaConnectManager:
    # -- Enable user kafka-connect-manager
    enabled: true

mirrormaker2:
  # -- Enable replication in the target (passive) cluster.
  enabled: false
  source:
    # -- Source (active) cluster to replicate from.
    bootstrapServer: ""
    # -- Topic replication from the source cluster defined as a comma-separated list or regular expression pattern.
    topicsPattern: "registry-schemas, lsst.sal.*"
  replication:
    policy:
      # -- Convention used to rename topics when the DefaultReplicationPolicy replication policy is used. Default is "" when the IdentityReplicationPolicy replication policy is used.
      # @default -- ""
      separator: ""
      # -- Replication policy.
      # @default -- IdentityReplicationPolicy
      class: "org.apache.kafka.connect.mirror.IdentityReplicationPolicy"
  sourceRegistry:
    # -- Whether to deploy another Schema Registry for the schemas replicated from the source cluster.
    enabled: false
    # -- Name of the topic Schema Registry topic replicated from the source cluster
    schemaTopic: "source.registry-schemas"
  sourceConnect:
    # -- Whether to deploy another Connect cluster for topics replicated from the source cluster.
    # Requires the sourceRegistry enabled.
    enabled: false
